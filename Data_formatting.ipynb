{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea6b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e11a44",
   "metadata": {},
   "source": [
    "## Making grand_dict \n",
    "w/ keys: filename, delimeter, encoding, filetype, grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdcfa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = '../Market_Data-Municipality_Level-20210915/'\n",
    "file_info = '''\n",
    "life_expectancy.csv ; latin_1 brick\n",
    "T2D.csv ; latin_1 brick\n",
    "Sales.csv , utf-8 other\n",
    "longterm_disease_.csv ; latin_1 brick\n",
    "andel_blodprop_i_hjertet.csv ; latin_1 brick\n",
    "patient_data.csv , utf-8 other\n",
    "attention.csv , utf-8 other\n",
    "svaert_overvaegt.csv ; latin_1 brick\n",
    "attention_3.csv ; utf-8 other\n",
    "svært_overvægt.csv ; latin_1 #\n",
    "attention_3.xls ; utf-8 #\n",
    "uddannelse_lang.csv ; latin_1 brick\n",
    "fravaer.csv ; latin_1 brick\n",
    "variables_explanations.xlsx ; utf-8 #\n",
    "fravær.csv ; latin_1 #\n",
    "who_minimums_fysisk_aktivitet.csv ; latin_1 brick'''.split('\\n')[1:]\n",
    "file_info = [location+i for i in file_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ed04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_dict = {}\n",
    "for i in file_info:\n",
    "    contents = i.split(' ')\n",
    "    #print(contents)\n",
    "    if contents[3] == '#':\n",
    "        pass\n",
    "    else:\n",
    "        name = contents[0].split('/')[2].split('.')[0]\n",
    "        grand_dict[name] = {\n",
    "            'filename' :contents[0],\n",
    "            'delimeter': contents[1],\n",
    "            'encoding':contents[2],\n",
    "            'filetype': contents[0].split('/')[2].split('.')[1],\n",
    "            'grouping' :contents[3]}\n",
    "grand_dict['life_expectancy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4030294",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in grand_dict.keys():\n",
    "    if grand_dict[i]['filetype'] == 'csv':\n",
    "        grand_dict[i]['dataframe'] = pd.read_csv(grand_dict[i]['filename'], \n",
    "                                                 delimiter=grand_dict[i]['delimeter'], \n",
    "                                                 encoding=grand_dict[i]['encoding'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce444488",
   "metadata": {},
   "source": [
    "## Dropping and renaming cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d73321",
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_dict['life_expectancy']['dataframe'].rename(columns={'år':'life_expectancy (yrs)'}, inplace=True)\n",
    "\n",
    "grand_dict['T2D']['dataframe'].drop(columns=['brick'],inplace=True)\n",
    "\n",
    "grand_dict['longterm_disease_']['dataframe'].rename(columns={'anddel':'longterm_disease_anddel'}, inplace=True)\n",
    "grand_dict['longterm_disease_']['dataframe'].drop(columns=['brick'],inplace=True)\n",
    "\n",
    "grand_dict['andel_blodprop_i_hjertet']['dataframe'].drop(columns=['brick'],inplace=True)\n",
    "\n",
    "grand_dict['patient_data']['dataframe'].drop(columns=['Unnamed: {}'.format(i) for i in range(4,13)],inplace=True)\n",
    "\n",
    "grand_dict['svaert_overvaegt']['dataframe'].drop(columns=['brick'],inplace=True)\n",
    "grand_dict['svaert_overvaegt']['dataframe'].rename(columns={'Andel':'svaert_overvaegt Andel'}, inplace=True)\n",
    "\n",
    "grand_dict['attention_3']['dataframe'].drop(columns=['BRICK_NAME'],inplace=True)\n",
    "grand_dict['attention_3']['dataframe'].dropna(inplace=True)\n",
    "grand_dict['attention_3']['dataframe'].rename(columns={'BRICK_NO':'brick_nr'}, inplace=True)\n",
    "grand_dict['attention_3']['dataframe'] = grand_dict['attention_3']['dataframe'][grand_dict['attention_3']['dataframe']['brick_nr'] != 'Outside DK']\n",
    "grand_dict['attention_3']['dataframe']['brick_nr'] = grand_dict['attention_3']['dataframe']['brick_nr'].apply(lambda x: int(x))\n",
    "\n",
    "grand_dict['uddannelse_lang']['dataframe'].drop(columns=['brick', 'brick_navn', 'population'],inplace=True)\n",
    "grand_dict['uddannelse_lang']['dataframe'].rename(columns={'antal':'uddannelse_lang antal', 'value_per_1000' : 'uddannelse_lang (value_per_1000)'}, inplace=True)\n",
    "\n",
    "grand_dict['fravaer']['dataframe'].drop(columns=['brick'],inplace=True)\n",
    "\n",
    "grand_dict['who_minimums_fysisk_aktivitet']['dataframe'].drop(columns=['brick'],inplace=True)\n",
    "grand_dict['who_minimums_fysisk_aktivitet']['dataframe'].rename(columns={'Andel':'who_minimums_fysisk_aktivitet Andel'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da27e353",
   "metadata": {},
   "source": [
    "## Combining dfs of equal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56290990",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = []\n",
    "for key in grand_dict.keys():\n",
    "    if grand_dict[key]['grouping'] == 'brick':\n",
    "        \n",
    "        keys.append(key)\n",
    "dfs_brick = [grand_dict[key]['dataframe'] for key in keys]        \n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,on='brick_nr'), dfs_brick)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c28098a",
   "metadata": {},
   "source": [
    "## What is missing?\n",
    "Lets print remaining .csv files and the number of unique elements in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534ec5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in grand_dict.keys():\n",
    "    if grand_dict[key]['grouping'] != 'brick':\n",
    "        print(key)\n",
    "        for col in grand_dict[key]['dataframe'].columns:\n",
    "            print(col, grand_dict[key]['dataframe'][col].nunique())\n",
    "        print(len(grand_dict[key]['dataframe'][col]),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d439c16",
   "metadata": {},
   "source": [
    "### attention_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad44a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we should be able to get attention_3 to fit in the brick group\n",
    "new_attention_3 = df_final[['brick_nr']].copy()\n",
    "new_attention_3['fake'] = np.zeros(len(new_attention_3))\n",
    "df = grand_dict['attention_3']['dataframe'].copy()\n",
    "for WHO_ATC_CODE in df['WHO_ATC_CODE'].unique():\n",
    "    for PERIOD_ID in df['PERIOD_ID'].unique():\n",
    "        for SITE_SHORT in df['SITE_SHORT'].unique():\n",
    "            temp = df[(df['WHO_ATC_CODE'] == WHO_ATC_CODE) & (df['PERIOD_ID'] == PERIOD_ID) & (df['SITE_SHORT'] == SITE_SHORT)].copy()\n",
    "            name = WHO_ATC_CODE+'_'+str(PERIOD_ID)+'_'+SITE_SHORT + '_COUNT'\n",
    "            temp.drop(columns=['WHO_ATC_CODE', 'PERIOD_ID', 'SITE_SHORT', 'CATEGORY'], inplace=True)\n",
    "            temp.rename(columns={'COUNT_':name}, inplace=True)\n",
    "            new_attention_3 = new_attention_3.join(temp.set_index('brick_nr'), on='brick_nr')\n",
    "\n",
    "new_attention_3.drop(columns=['fake'], inplace=True)\n",
    "#new_attention_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1734d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_min = {}\n",
    "dic_pro = {}\n",
    "\n",
    "df = grand_dict['attention_3']['dataframe'].copy()\n",
    "for i in df.index[:]:\n",
    "    WHO_ATC_CODE = df['WHO_ATC_CODE'][i]\n",
    "    brick_nr = df['brick_nr'][i]\n",
    "    SITE_SHORT = df['SITE_SHORT'][i]\n",
    "    PERIOD_ID = df['PERIOD_ID'][i]\n",
    "    \n",
    "    COUNT_ = df['COUNT_'][i]\n",
    "    #print('\\n',df.iloc[i])\n",
    "    \n",
    "    if SITE_SHORT == 'min':\n",
    "        dic = dic_min\n",
    "    else:\n",
    "        dic = dic_pro\n",
    "    \n",
    "    if WHO_ATC_CODE in dic.keys():\n",
    "        if brick_nr in dic[WHO_ATC_CODE].keys():\n",
    "            dic[WHO_ATC_CODE][brick_nr][PERIOD_ID] = COUNT_\n",
    "        else:\n",
    "            dic[WHO_ATC_CODE][brick_nr] = {PERIOD_ID: COUNT_}\n",
    "    else:\n",
    "        dic[WHO_ATC_CODE] = {brick_nr : {PERIOD_ID: COUNT_}}\n",
    "        \n",
    "    if SITE_SHORT == 'min':\n",
    "        dic_min = dic\n",
    "    else:\n",
    "        dic_pro = dic\n",
    "        \n",
    "        \n",
    "dic_min['A10AE04'][502]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25213ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_df = {k: pd.DataFrame(v) for k,v in dic_min.items()}\n",
    "df_attention_3_min = pd.concat(dict_of_df, axis=1).T\n",
    "\n",
    "dict_of_df = {k: pd.DataFrame(v) for k,v in dic_pro.items()}\n",
    "df_attention_3_pro = pd.concat(dict_of_df, axis=1).T\n",
    "\n",
    "#df_attention_3_min # /min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7e9707",
   "metadata": {},
   "source": [
    "### Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd472e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for sales\n",
    "\n",
    "# First lets grab a copy\n",
    "df = grand_dict['Sales']['dataframe'].copy()\n",
    "df = df[df['SECTOR_CODE']=='P']\n",
    "df.drop(columns=['SECTOR_CODE'], inplace=True)\n",
    "value_dict = {}\n",
    "volume_dict = {}\n",
    "\n",
    "for i in df.index:\n",
    "    MUNICIPALITY, WHO_ATC_CODE, YEAR_MONTH = df['MUNICIPALITY'][i], df['WHO_ATC_CODE'][i], df['YEAR_MONTH'][i]\n",
    "    VOLUME, VALUE = df['VOLUME'][i], df['VALUE'][i]\n",
    "    \n",
    "    if WHO_ATC_CODE in value_dict.keys():\n",
    "        if MUNICIPALITY in value_dict[WHO_ATC_CODE].keys():\n",
    "            value_dict[WHO_ATC_CODE][MUNICIPALITY][YEAR_MONTH] =VALUE\n",
    "            volume_dict[WHO_ATC_CODE][MUNICIPALITY][YEAR_MONTH] =VOLUME   \n",
    "        else:\n",
    "            value_dict[WHO_ATC_CODE][MUNICIPALITY] = {YEAR_MONTH :VALUE}\n",
    "            volume_dict[WHO_ATC_CODE][MUNICIPALITY] = {YEAR_MONTH :VOLUME}\n",
    "    else:\n",
    "        for dic, x in zip([value_dict, volume_dict],[VALUE, VOLUME]):\n",
    "            dic[WHO_ATC_CODE] = {}\n",
    "            dic[WHO_ATC_CODE][MUNICIPALITY]= {YEAR_MONTH: x}\n",
    "            \n",
    "            \n",
    "dict_of_df = {k: pd.DataFrame(v) for k,v in value_dict.items()}\n",
    "df_value = pd.concat(dict_of_df, axis=1)\n",
    "\n",
    "dict_of_df = {k: pd.DataFrame(v) for k,v in volume_dict.items()}\n",
    "df_volume = pd.concat(dict_of_df, axis=1)\n",
    "\n",
    "#df_value.T.head(3)\n",
    "#df_volume.T#.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a4faf5",
   "metadata": {},
   "source": [
    "### patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb264b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = grand_dict['patient_data']['dataframe'].copy()\n",
    "df_patient_data = pd.DataFrame(df[['n_type1','n_type2']].values, \n",
    "                   index=[\n",
    "                       df['Hospital'].values,\n",
    "                       df['Department'].values], \n",
    "                   columns='n_type1, n_type2'.split(', '))\n",
    "#df_patient_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a039ab",
   "metadata": {},
   "source": [
    "### attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e8c620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = grand_dict['attention']['dataframe'].copy()\n",
    "df['Region'] = df['REGIONNAME']+' '+ df['REGION'].astype(str)\n",
    "df['City'] = df['ZIP'].astype(str)+' '+ df['CITY']\n",
    "df.drop(columns='CITY, REGION, REGIONNAME, ZIP'.split(', '), inplace=True)\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c500fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks_dict_pro = {} # ZIP = {}, \n",
    "clicks_dict_min = {}\n",
    "\n",
    "for i in df.index[:]:\n",
    "    Region,City , WHO_ATC_CODE, YEAR_MONTH = df['Region'][i], df['City'][i], df['WHO_ATC_5_DERIVED'][i], df['PERIOD_YEAR_MONTH_NUM'][i]\n",
    "    clicks, SITE_SHORT = df['CLICKS'][i], df['SITE_SHORT'][i]\n",
    "    #print(Region)\n",
    "    if SITE_SHORT == 'pro':\n",
    "        if Region in clicks_dict_pro.keys():\n",
    "            if City in clicks_dict_pro[Region].keys():\n",
    "                if WHO_ATC_CODE in clicks_dict_pro[Region][City].keys():\n",
    "                    clicks_dict_pro[Region][City][WHO_ATC_CODE][YEAR_MONTH] = clicks\n",
    "                else:\n",
    "                    clicks_dict_pro[Region][City][WHO_ATC_CODE] = {YEAR_MONTH: clicks}\n",
    "            else:\n",
    "                clicks_dict_pro[Region][City] = {WHO_ATC_CODE :{YEAR_MONTH :clicks}}\n",
    "        else:\n",
    "            clicks_dict_pro[Region] = {}\n",
    "            clicks_dict_pro[Region][City]= {WHO_ATC_CODE: {YEAR_MONTH : clicks}}\n",
    "    else:\n",
    "        if Region in clicks_dict_min.keys():\n",
    "            if City in clicks_dict_min[Region].keys():\n",
    "                if WHO_ATC_CODE in clicks_dict_min[Region][City].keys():\n",
    "                    clicks_dict_min[Region][City][WHO_ATC_CODE][YEAR_MONTH] = clicks\n",
    "                else:\n",
    "                    clicks_dict_min[Region][City][WHO_ATC_CODE] = {YEAR_MONTH: clicks}\n",
    "            else:\n",
    "                clicks_dict_min[Region][City] = {WHO_ATC_CODE :{YEAR_MONTH :clicks}}\n",
    "        else:\n",
    "            clicks_dict_min[Region] = {}\n",
    "            clicks_dict_min[Region][City]= {WHO_ATC_CODE: {YEAR_MONTH : clicks}}\n",
    "#clicks_dict_pro\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f45cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reform = {(level1_key, level2_key, level3_key): values\n",
    "   ...:           for level1_key, level2_dict in clicks_dict_min.items()\n",
    "   ...:           for level2_key, level3_dict in level2_dict.items()\n",
    "   ...:           for level3_key, values      in level3_dict.items()}\n",
    "df_attention_clicks_min = pd.DataFrame(reform).T\n",
    "\n",
    "reform = {(level1_key, level2_key, level3_key): values\n",
    "   ...:           for level1_key, level2_dict in clicks_dict_pro.items()\n",
    "   ...:           for level2_key, level3_dict in level2_dict.items()\n",
    "   ...:           for level3_key, values      in level3_dict.items()}\n",
    "df_attention_clicks_pro = pd.DataFrame(reform).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80be760a",
   "metadata": {},
   "source": [
    "## Now lets save all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da8a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_value.T.to_csv('../Cleaned_Market_data_anton/df_value.csv')\n",
    "df_volume.T.to_csv('../Cleaned_Market_data_anton/df_volume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe3637",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = '../antonsdata/'\n",
    "\n",
    "# bricks\n",
    "df_final.to_csv(loc+'df_bricks.csv')\n",
    "\n",
    "# Attention 3\n",
    "df_attention_3_min.to_csv(loc+'new_attention_3_min.csv')\n",
    "df_attention_3_pro.to_csv(loc+'new_attention_3_pro.csv')\n",
    "\n",
    "# Sales\n",
    "df_value.T.to_csv(loc+'df_value.csv')\n",
    "df_volume.T.to_csv(loc+'df_volume.csv')\n",
    "\n",
    "# Patient data\n",
    "df_patient_data.to_csv(loc+'df_patient_data.csv')\n",
    "\n",
    "# attention\n",
    "df_attention_clicks_min.to_csv(loc+'df_attention_clicks_min.csv')\n",
    "df_attention_clicks_pro.to_csv(loc+'df_attention_clicks_pro.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478ba809",
   "metadata": {},
   "source": [
    "## And try loading them again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53b3337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bricks\n",
    "dfA = pd.read_csv(loc+'df_bricks.csv',index_col=[0],decimal= ',')\n",
    "\n",
    "# Attention 3\n",
    "dfB1 = pd.read_csv(loc+'new_attention_3_pro.csv',index_col=[0,1])\n",
    "dfB2 = pd.read_csv(loc+'new_attention_3_min.csv',index_col=[0,1])\n",
    "\n",
    "# Sales\n",
    "dfC1 = pd.read_csv(loc+'df_value.csv',index_col=[0,1])\n",
    "dfC2 = pd.read_csv(loc+'df_volume.csv',index_col=[0,1])\n",
    "\n",
    "# Patient data\n",
    "dfD = pd.read_csv(loc+'df_patient_data.csv',index_col=[0,1])\n",
    "\n",
    "# attention\n",
    "\n",
    "dfE1 = pd.read_csv(loc+'df_attention_clicks_min.csv',index_col=[0,1,2])\n",
    "dfE2 = pd.read_csv(loc+'df_attention_clicks_pro.csv',index_col=[0,1,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
